# -*- coding: utf-8 -*-
"""House Price Prediction Using Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AOZA5r7RaszKn1tVhUyAecE7O4Pt-Boe

# **BHARAT INTERN MACHINE LEARNING**

1.   **Name** : MALISETTI RAMNARAYANA
2.   **Persuing** : COMPUTER SCIENCE & ENGINEERING WITH ARTIFICIAL INTELLIGENCE & MACHINE LEARNING 3rd Year

Title of the project  :   **House Price Prediction**

## House Price Prediction
"""

dataset_link = "/content/housing1.csv"

"""## Importing the Dataset"""

import numpy as np
import pandas as pd

dataset = pd.read_csv(dataset_link)

dataset.head()  # here we display the few samples in the dataset

dataset.info()  # here this info() method prints the information about the dataframe.

"""### Checking  for NAN values in dataset ..."""

dataset.isna().sum()

"""### Replace the missing values.."""

dataset = dataset.fillna(dataset.mean())

dataset

"""#Univariate Regression

### Seggregating the data into features and labels
"""

x_data = dataset['sqft_living']
y_data = dataset['price']

x_data

"""### Creating each single feature as a vector"""

# Create each single feature as a vector
x_data = np.array(x_data).reshape((-1,1))
print(x_data)

"""### Splitting the data into train and test .."""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)
print("shape of training samples:",x_train.shape)
print("shape of test samples :", x_test.shape)
print("shape of train labels :", y_train.shape)
print("shape of test labels:",y_test.shape)

"""### Importing the required packages.."""

import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

"""### Build a model using LinearRegression"""

from numpy.ma.core import nonzero
lre=LinearRegression()
lre.fit(x_train,y_train)

print("Intercept is ",lre.intercept_,"\n","Coef is",lre.coef_)

r_squared = lre.score(x_test, y_test)
print("R Square value is ",r_squared)

y_pred = lre.predict(x_test)
print(f"predicted response:\n{y_pred}")

from sklearn.metrics import mean_squared_error
MSE = mean_squared_error(y_test, y_pred)
RMSE = mean_squared_error(y_test, y_pred, squared=False)
print("MSE is:", MSE)
print("RMSE is:", RMSE)
print("R_squared is:", r_squared)

"""# Multivariate Regression"""

x_data = dataset[[ 'bedrooms','bathrooms','sqft_living']]
y_data = dataset['price']

x_data.head()

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)
print("shape of training samples:",x_train.shape)
print("shape of test samples :", x_test.shape)
print("shape of train labels :", y_train.shape)
print("shape of test labels:",y_test.shape)

import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
lre=LinearRegression()

lre.fit(x_train,y_train)

print("Intercept is ",lre.intercept_,"\n","Coefficients are",lre.coef_)

r_squared = lre.score(x_test, y_test)
print("R Square value is ",r_squared)

y_pred = lre.predict(x_test)
print(f"predicted response:\n{y_pred}")

from sklearn.metrics import mean_squared_error
MSE = mean_squared_error(y_test, y_pred)
RMSE = mean_squared_error(y_test, y_pred, squared=False)
print("MSE is:", MSE)
print("RMSE is:", RMSE)
print("R_squared is:", r_squared)

"""# Observe Variance Inflation Factor(VIF)

"""

!pip install statsmodels --upgrade

from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm

X = dataset[['sqft_living', 'bedrooms', 'bathrooms']]
y = dataset['price']

"""### Add constant to predictor variables for intercept term"""

X = sm.add_constant(X)

"""### Compute VIF for each predictor variable"""

vif = pd.DataFrame()
vif["VIF Factor"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif["predictor"] = X.columns

print(vif)

"""# Implement Ridge Regression Model"""

x_data = dataset['sqft_living']
y_data = dataset['price']

"""### Create each single feature as a vector.."""

x_data = np.array(x_data).reshape((-1,1))

x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

ridge_model = Ridge(alpha=0.0)

ridge_model.fit(x_train, y_train)

y_pred = ridge_model.predict(x_test)

print("RSquared Error : ", ridge_model.score(x_test,y_test))
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error: ", mse)

"""# LASSO Regression Model"""

from sklearn import datasets
from sklearn.linear_model import Lasso

"""### Create an instance of Lasso Regression implementation"""

lasso = Lasso(alpha=0.2)

"""### Fit the Lasso model"""

lasso.fit(x_train, y_train)
y_pred = lasso.predict(x_test)

"""### Evaluate the model score"""

print("Model Score : ",lasso.score(x_test, y_test))
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error: ", mse)

"""# Observation on above models

**For Univariate model**
"""

X = dataset['sqft_living']
y = dataset['price']

"""### Calculate the slope and intercept of the best-fit line"""

slope = np.sum((X - np.mean(X)) * (y - np.mean(y))) / np.sum((X - np.mean(X)) ** 2)
intercept = np.mean(y) - slope * np.mean(X)

print(slope, intercept)

lre=LinearRegression()
lre.fit(np.array(X).reshape((-1,1)),y)
pred_slope = lre.coef_
pred_intercept = lre.intercept_

print(pred_slope, pred_intercept)

"""### Plot the scatter plot and the best-fit line

**For univariate model**
"""

import matplotlib.pyplot as plt
plt.scatter(X, y)
plt.plot(X, slope * X + intercept, color='red')
plt.xlabel('sqft')
plt.ylabel('price')
plt.show()

import matplotlib.pyplot as plt
plt.scatter(X, y)
plt.plot(X, slope * X + intercept, color='red')
plt.plot(X, pred_slope * X + pred_intercept, color='green')
plt.legend(['sample','actual','predicted'])
plt.xlabel('sqft')
plt.ylabel('price')
plt.show()

"""**For Multivariate model**"""

import numpy as np
import matplotlib.pyplot as plt

# input features
sqft = dataset['sqft_living']
bedrooms = dataset['bedrooms']
bathrooms = dataset['bathrooms']

# target variable
price = dataset['price']

# combine input features into a single matrix
X = np.column_stack((sqft, bedrooms, bathrooms))

# add a column of ones for the intercept term
X = np.hstack((np.ones((len(X), 1)), X))

# calculate the least squares solution for the model coefficients
w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(price)

# calculate predicted values of the target variable
y_pred = X.dot(w)

# plot the scatter plot and best-fit line
fig, ax = plt.subplots()
ax.scatter(sqft, price)
ax.plot(sqft, y_pred, color='red')
ax.set_xlabel('Square Feet')
ax.set_ylabel('Price')
plt.show()